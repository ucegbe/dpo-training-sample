This sample contains code for finetuning a qwen model using DPO.
`train` notebook contains logic for training an LLM using distributed training
`automatic-hyperparameter-optimization/train-hpo` notebook contains logic on how to use SageMaker automatic model finetuning feature for hyperparameter optimization on a RFT job.
